{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6e873b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Arquivo gerado: knapPI_14_200_1000_1_items.txt\n",
      "✓ Arquivo gerado: knapPI_1_500_1000_1_items.txt\n",
      "✓ Arquivo gerado: knapPI_2_500_1000_1_items.txt\n",
      "✓ Arquivo gerado: knapPI_3_500_1000_1_items.txt\n"
     ]
    }
   ],
   "source": [
    "#normalizar os arquivos de teste\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "raiz = \"large_scale\"\n",
    "\n",
    "meta = \"large_scale_trated\"\n",
    "\n",
    "\n",
    "all_files = sorted([os.path.join(root, f) for root, _, files in os.walk(raiz) for f in files])\n",
    "for i in range(0, len(all_files),2):\n",
    "    info_file = all_files[i]\n",
    "    items_file = all_files[i+1]\n",
    "\n",
    "    info_df = pd.read_csv(info_file, header=None)\n",
    "    for index, row in info_df.iterrows():\n",
    "        if row[0] == 'n':\n",
    "            n = int(row[1])\n",
    "        elif row[0] == 'c':\n",
    "            W = int(row[1])\n",
    "\n",
    "    # Processa o arquivo items correspondente\n",
    "    items_df = pd.read_csv(items_file)[[' price', ' weight']]\n",
    "        \n",
    "    # Adiciona n e W como primeira linha\n",
    "    modified_df = pd.concat([\n",
    "        pd.DataFrame([[n, W]], columns=items_df.columns),\n",
    "        items_df\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    base_name = os.path.basename(items_file).split('.')[0]  # Remove extensão\n",
    "    output_file = os.path.join(meta, f\"{base_name}.txt\")\n",
    "        \n",
    "        # Salva como TXT com espaços\n",
    "    with open(output_file, 'w') as f:\n",
    "        for _, row in modified_df.iterrows():\n",
    "            f.write(f\"{int(row[0])} {int(row[1])}\\n\")\n",
    "    \n",
    "    print(f\"✓ Arquivo gerado: {os.path.basename(output_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b03ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame consolidado:\n",
      "     Tipo    N      W Peso_avg Peso_max Valor_avg Valor_max   Sol BB Tempo BB  \\\n",
      "0   Large  200    997   498.09      997    711.59      1230     5397     1586   \n",
      "1   Large  500   2543  513.864      997   494.142       998    28857   804097   \n",
      "2   Large  500   2543  513.864      997   516.634      1074     4566    45777   \n",
      "3   Large  500   2517  508.612      998   608.612      1098     7117   741009   \n",
      "4     Low   20    879     54.9       96      54.3        91     1025     2657   \n",
      "5     Low   10    269     53.9       95      41.2        87      295       25   \n",
      "6     Low   20    878     54.9       96     54.25        91     1024     2550   \n",
      "7     Low    4     20     6.75        9        12        15       35        9   \n",
      "8     Low    4     11     4.75        7     10.25        13       23       12   \n",
      "9     Low   15    375  49.4611  89.5962   37.5331   98.8525  481.069       38   \n",
      "10    Low   10     60       13       30      10.5        20       52      111   \n",
      "11    Low    7     50  13.2857       31   26.8571        70      107       16   \n",
      "12    Low   23  10000  844.696      983   839.522       981     9767   189635   \n",
      "13    Low    5     80     18.2       31      28.4        37      130       15   \n",
      "\n",
      "   Custo BB Sol 2-Aprox Tempo 2-Aprox Custo 2-Aprox  \n",
      "0      1916        5397        332028         77956  \n",
      "1      1908       28857     1282910.0        988704  \n",
      "2      1920        4566     1261390.0        960116  \n",
      "3      1916        7117        675403       1104620  \n",
      "4      1904        1025          1005          3780  \n",
      "5      1924         293            68          1900  \n",
      "6      1924        1024           462          3844  \n",
      "7      1900          35            19          1896  \n",
      "8      1916          23            19          1904  \n",
      "9      1920     481.069           104          1864  \n",
      "10     1860          52            97          1864  \n",
      "11     1920         107            29          1916  \n",
      "12     1924        9714           812          3724  \n",
      "13     1920         130            41          1900  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_file(path, name):\n",
    "    data = []\n",
    "    current_test = {}  # Armazenará os dados completos de um teste (BB + Aprox)\n",
    "    last_method = None\n",
    "    \n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Parse Número de Total de Itens e Peso máximo\n",
    "            if line.startswith('* Número de itens: '):\n",
    "                # Se já temos dados do método anterior, prepara para novo teste\n",
    "                if last_method == '2-aproximativo':\n",
    "                    data.append(current_test)\n",
    "                    current_test = {}\n",
    "                \n",
    "                current_test['N'] = line.split(': ')[1].strip()\n",
    "            \n",
    "\n",
    "            elif line.startswith('* Peso médio:'):\n",
    "                current_test['Peso_avg'] = line.split(': ')[1].strip()\n",
    "            elif line.startswith('* Peso máximo:'):\n",
    "                current_test['Peso_max'] = line.split(': ')[1].strip()\n",
    "            elif line.startswith('* Valor médio:'):\n",
    "                current_test['Valor_avg'] = line.split(': ')[1].strip()\n",
    "            elif line.startswith('* Valor máximo:'):\n",
    "                current_test['Valor_max'] = line.split(': ')[1].strip()\n",
    "            elif line.startswith('* Capacidade da Mochila:'):\n",
    "                current_test['W'] = line.split(': ')[1].strip()\n",
    "\n",
    "            # Parse Branch and Bound value\n",
    "            elif line.startswith('Branch and Bound:'):\n",
    "                current_test['BB_sol'] = line.split(': ')[1].strip()\n",
    "                last_method = 'BB'\n",
    "            # Parse 2-aproximativo value\n",
    "            elif line.startswith('2-aproximativo:'):\n",
    "                current_test['Aprox_sol'] = line.split(': ')[1].strip()\n",
    "                last_method = '2-aproximativo'\n",
    "            # Parse Branch and Bound time\n",
    "            elif line.startswith('Tempo Branch and Bound :'):\n",
    "                current_test['BB_time'] = line.split(': ')[1].strip()\n",
    "            # Parse Aproximativo time\n",
    "            elif line.startswith('Tempo Aproximativo :'):\n",
    "                current_test['Aprox_time'] = line.split(': ')[1].strip()\n",
    "            # Parse RSS memory for BB\n",
    "            elif line.startswith('* Memória residente real (RSS):') and '[BB]' in current_test.get('last_section', ''):\n",
    "                current_test['BB_mem'] = line.split(': ')[1].replace(' KB', '').strip()\n",
    "            # Parse RSS memory for aprox\n",
    "            elif line.startswith('* Memória residente real (RSS):') and '[aprox]' in current_test.get('last_section', ''):\n",
    "                current_test['Aprox_mem'] = line.split(': ')[1].replace(' KB', '').strip()\n",
    "                current_test['Type'] = name\n",
    "            # Track current section\n",
    "            elif line.startswith('=== Métricas de Memória'):\n",
    "                current_test['last_section'] = line\n",
    "    \n",
    "    # Add the last test if exists\n",
    "    if current_test:\n",
    "        data.append(current_test)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Process both files\n",
    "df_large = parse_file(\"large_results.txt\", \"Large\")\n",
    "df_low = parse_file(\"low_results.txt\", \"Low\")\n",
    "\n",
    "# Combine both DataFrames\n",
    "df_combined = pd.concat([df_large, df_low], ignore_index=True)\n",
    "\n",
    "# Convert scientific notation to normal numbers and clean data\n",
    "def clean_value(val):\n",
    "    if not isinstance(val, str):\n",
    "        return val\n",
    "    if 'e+' in val:\n",
    "        return str(float(val))\n",
    "    return val.replace(' KB', '')\n",
    "\n",
    "df_combined = df_combined.applymap(clean_value)\n",
    "\n",
    "# Reorder columns\n",
    "columns = ['Type', 'N', 'W','Peso_avg','Peso_max','Valor_avg','Valor_max','Sol BB', 'Tempo BB', 'Custo BB', \n",
    "           'Sol 2-Aprox', 'Tempo 2-Aprox', 'Custo 2-Aprox']\n",
    "df_combined = df_combined[columns]\n",
    "\n",
    "# Fill empty values with empty string for better CSV output\n",
    "df_combined = df_combined.fillna('')\n",
    "\n",
    "# Save to CSV\n",
    "df_combined.to_csv('resultados_combinados.csv', index=False)\n",
    "\n",
    "print(\"DataFrame consolidado:\")\n",
    "print(df_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
